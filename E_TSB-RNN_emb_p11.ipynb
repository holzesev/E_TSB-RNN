{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, multilabel_confusion_matrix, confusion_matrix\r\n",
    "\r\n",
    "# Seed value\r\n",
    "seed_value= 0\r\n",
    "\r\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\r\n",
    "import os\r\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\r\n",
    "\r\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\r\n",
    "import random\r\n",
    "random.seed(seed_value)\r\n",
    "\r\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\r\n",
    "import numpy as np\r\n",
    "np.random.seed(seed_value)\r\n",
    "\r\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\r\n",
    "import tensorflow as tf\r\n",
    "tf.random.set_seed(seed_value)\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "import raha\r\n",
    "\r\n",
    "del seed_value"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1) Input: We load both datasets (dirty and clean) as dirty_table and clean_table."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Load Data\r\n",
    "data='Tax'\r\n",
    "\r\n",
    "dirty_table = pd.read_csv('./datasets/' + data + '/dirty.csv', sep=\",\", header=\"infer\", encoding=\"utf-8\", dtype=str, keep_default_na=False, low_memory=False)\r\n",
    "clean_table = pd.read_csv('./datasets/' + data + '/clean.csv', sep=\",\", header=\"infer\", encoding=\"utf-8\", dtype=str, keep_default_na=False, low_memory=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2) Structure Transformation: Next we rename the column names in the dirty_table to have identical names with the clean dataset. We need this to combine the information of both datasets and create a new one (df). Also we add tid as sequence number for every row. At the end we cute the strings after 100 characters (numcharmax)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Structure dirty_table and clean_table equal? (names of columns can be different)\r\n",
    "Tablestructure_equal = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Rename the different columnames\r\n",
    "cols_clean_table = list(clean_table.columns.values)\r\n",
    "cols_dirty_table = list(dirty_table.columns.values)\r\n",
    "\r\n",
    "if sorted(cols_clean_table) == sorted(cols_dirty_table): \r\n",
    "    print (\"The lists are identical\")\r\n",
    "else : \r\n",
    "    print (\"The lists are not identical\")\r\n",
    "    if Tablestructure_equal == True:\r\n",
    "        print (\"The dirty and clean have the same structure. We use the columnames from clean for dirty.\") \r\n",
    "        dirty_table.columns = cols_clean_table\r\n",
    "\r\n",
    "del cols_clean_table, cols_dirty_table, Tablestructure_equal"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The lists are identical\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Add id_\r\n",
    "clean_table.insert(0, 'id_', clean_table.index)\r\n",
    "clean_table = clean_table.set_index('id_')\r\n",
    "\r\n",
    "dirty_table.insert(0, 'id_', dirty_table.index)\r\n",
    "dirty_table = dirty_table.set_index('id_')\r\n",
    "\r\n",
    "dirty_table = dirty_table.replace(r'^\\s*$', np.nan, regex=True)\r\n",
    "dirty_table = dirty_table.fillna('')\r\n",
    "clean_table = clean_table.replace(r'^\\s*$', np.nan, regex=True)\r\n",
    "clean_table = clean_table.fillna('')\r\n",
    "\r\n",
    "# Generate table attribute with information about columns\r\n",
    "attribute = pd.DataFrame(clean_table.columns.to_numpy(), columns = ['name'])\r\n",
    "measurer = np.vectorize(len)\r\n",
    "attribute['maxnumchar1'] = measurer(dirty_table.astype(str)).max(axis=0)\r\n",
    "attribute['maxnumchar']=np.where(attribute['maxnumchar1']>128, 128, attribute['maxnumchar1'])\r\n",
    "\r\n",
    "del measurer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3) Merge: Next we combine the two tables in the dataset df where every cell of the dirty_table / clean_table is saved in the columns value_x / value_y, respectively. For the models we need an attribute value, i.e. a label, which includes 0 (correct) or 1 (wrong). We get this value when comparing value_x and value_y."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Produce datasets which transformed the table in rows\r\n",
    "clean_row=clean_table.unstack().reset_index()\r\n",
    "clean_row['Sort'] = clean_row.index\r\n",
    "clean_row = clean_row.rename(columns={'level_0':'attribute','level_1':'id_',0:'value'}).sort_values(by=['id_','Sort'])\r\n",
    "clean_row=clean_row.reset_index(drop=True).drop(columns='Sort')\r\n",
    "\r\n",
    "dirty_row=dirty_table.unstack().reset_index()\r\n",
    "dirty_row['Sort'] = dirty_row.index\r\n",
    "dirty_row = dirty_row.rename(columns={'level_0':'attribute','level_1':'id_',0:'value'}).sort_values(by=['id_','Sort'])\r\n",
    "dirty_row=dirty_row.reset_index(drop=True).drop(columns='Sort')\r\n",
    "\r\n",
    "# Produce datasets for M2\r\n",
    "X_roh = dirty_table\r\n",
    "y = clean_table != dirty_table\r\n",
    "\r\n",
    "y = y.astype(int)\r\n",
    "\r\n",
    "del dirty_table, clean_table"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Merge datasets together\r\n",
    "df = pd.merge(dirty_row, clean_row, on=['id_', \"attribute\"])\r\n",
    "\r\n",
    "# Show rows which are empty (1)\r\n",
    "df['empty1'] = np.where(df['value_x'] == '', 1, 0)\r\n",
    "\r\n",
    "# Compare content of dirty and clean dataset\r\n",
    "df['value'] = np.where(df['value_x'] == df['value_y'], 0, 1)\r\n",
    "\r\n",
    "# Concatenate attributename and value_x (dirty)\r\n",
    "df['concat'] = df['attribute'] + '_' + df.value_x.fillna('')\r\n",
    "\r\n",
    "df['length'] = df.value_x.fillna('').str.len()\r\n",
    "\r\n",
    "del dirty_row, clean_row"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Save all possible 'id_' in a dataset\r\n",
    "ID_Alle = df.groupby(['id_'], as_index=False)['value'].sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   attribute  id_   value_x   value_y  empty1  value           concat  length\n",
       "0     f_name    0  Pengyuan  Pengyuan       0      0  f_name_Pengyuan       8\n",
       "1     l_name    0   Zendler   Zendler       0      0   l_name_Zendler       7\n",
       "2     gender    0         F         F       0      0         gender_F       1\n",
       "3  area_code    0       508       508       0      0    area_code_508       3\n",
       "4      phone    0  744-9007  744-9007       0      0   phone_744-9007       8"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute</th>\n",
       "      <th>id_</th>\n",
       "      <th>value_x</th>\n",
       "      <th>value_y</th>\n",
       "      <th>empty1</th>\n",
       "      <th>value</th>\n",
       "      <th>concat</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f_name</td>\n",
       "      <td>0</td>\n",
       "      <td>Pengyuan</td>\n",
       "      <td>Pengyuan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f_name_Pengyuan</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l_name</td>\n",
       "      <td>0</td>\n",
       "      <td>Zendler</td>\n",
       "      <td>Zendler</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>l_name_Zendler</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gender</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gender_F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>area_code</td>\n",
       "      <td>0</td>\n",
       "      <td>508</td>\n",
       "      <td>508</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>area_code_508</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phone</td>\n",
       "      <td>0</td>\n",
       "      <td>744-9007</td>\n",
       "      <td>744-9007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>phone_744-9007</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "df.dtypes"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "attribute    object\n",
       "id_           int64\n",
       "value_x      object\n",
       "value_y      object\n",
       "empty1        int32\n",
       "value         int32\n",
       "concat       object\n",
       "length        int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Print properties (length and number of errors per column)\r\n",
    "num_error_col=0\r\n",
    "for attr in attribute['name']:\r\n",
    "    df2 = df[df['attribute']==attr]\r\n",
    "    maxnumchar = attribute.loc[attribute['name']==attr]['maxnumchar'].to_numpy()[0]\r\n",
    "    maxnumchar1 = attribute.loc[attribute['name']==attr]['maxnumchar1'].to_numpy()[0]\r\n",
    "    summe = np.sum(df2.value)\r\n",
    "    attribute.loc[attribute['name'] == attr, 'error'] = int(summe)\r\n",
    "    print(attr)\r\n",
    "    print('Max lenght: ' + str(maxnumchar1) + ' --> ' + str(maxnumchar))\r\n",
    "    print('Number of errors: ' + str(summe))\r\n",
    "    print('')\r\n",
    "    if summe > 0:\r\n",
    "        num_error_col+=1\r\n",
    "\r\n",
    "print(str(num_error_col) + '/' + str(len(attribute)) + ' faulty attributes')\r\n",
    "del attr, df2, summe, num_error_col, maxnumchar, maxnumchar1"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "f_name\n",
      "Max lenght: 17 --> 17\n",
      "Number of errors: 272\n",
      "\n",
      "l_name\n",
      "Max lenght: 18 --> 18\n",
      "Number of errors: 694\n",
      "\n",
      "gender\n",
      "Max lenght: 1 --> 1\n",
      "Number of errors: 0\n",
      "\n",
      "area_code\n",
      "Max lenght: 3 --> 3\n",
      "Number of errors: 0\n",
      "\n",
      "phone\n",
      "Max lenght: 8 --> 8\n",
      "Number of errors: 0\n",
      "\n",
      "city\n",
      "Max lenght: 27 --> 27\n",
      "Number of errors: 200\n",
      "\n",
      "state\n",
      "Max lenght: 4 --> 4\n",
      "Number of errors: 600\n",
      "\n",
      "zip\n",
      "Max lenght: 5 --> 5\n",
      "Number of errors: 31311\n",
      "\n",
      "marital_status\n",
      "Max lenght: 1 --> 1\n",
      "Number of errors: 200\n",
      "\n",
      "has_child\n",
      "Max lenght: 1 --> 1\n",
      "Number of errors: 200\n",
      "\n",
      "salary\n",
      "Max lenght: 6 --> 6\n",
      "Number of errors: 0\n",
      "\n",
      "rate\n",
      "Max lenght: 9 --> 9\n",
      "Number of errors: 87342\n",
      "\n",
      "single_exemp\n",
      "Max lenght: 5 --> 5\n",
      "Number of errors: 200\n",
      "\n",
      "married_exemp\n",
      "Max lenght: 5 --> 5\n",
      "Number of errors: 0\n",
      "\n",
      "child_exemp\n",
      "Max lenght: 4 --> 4\n",
      "Number of errors: 200\n",
      "\n",
      "10/15 faulty attributes\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "attribute"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              name  maxnumchar1  maxnumchar    error\n",
       "0           f_name           17          17    272.0\n",
       "1           l_name           18          18    694.0\n",
       "2           gender            1           1      0.0\n",
       "3        area_code            3           3      0.0\n",
       "4            phone            8           8      0.0\n",
       "5             city           27          27    200.0\n",
       "6            state            4           4    600.0\n",
       "7              zip            5           5  31311.0\n",
       "8   marital_status            1           1    200.0\n",
       "9        has_child            1           1    200.0\n",
       "10          salary            6           6      0.0\n",
       "11            rate            9           9  87342.0\n",
       "12    single_exemp            5           5    200.0\n",
       "13   married_exemp            5           5      0.0\n",
       "14     child_exemp            4           4    200.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>maxnumchar1</th>\n",
       "      <th>maxnumchar</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f_name</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l_name</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>694.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gender</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>area_code</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phone</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>city</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>state</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>zip</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>31311.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>marital_status</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>has_child</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>salary</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rate</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>87342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>single_exemp</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>married_exemp</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>child_exemp</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "4) Dictionary Generation: Before we can feed the data into a neural network, we need to transform the data types from character to numeric character embedding. We produce a value dictionary (char_index) which contains an index for each character in value_x.\n",
    "\n",
    "For the ETSB-RNN we also need an attribute dictionary (attribute_index) which includes an index for each attribute."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "maxlen = np.max(attribute['maxnumchar'])\r\n",
    "print(\"Maximum value_x length: \", maxlen)\r\n",
    "Summe = df.groupby('value')['id_'].count()\r\n",
    "print(Summe)\r\n",
    "print()\r\n",
    "print('Error Rate:'+ str(round(100/(Summe[0]+Summe[1])*Summe[1],2)))\r\n",
    "\r\n",
    "del Summe"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Maximum value_x length:  27\n",
      "value\n",
      "0    2878781\n",
      "1     121219\n",
      "Name: id_, dtype: int64\n",
      "\n",
      "Error Rate:4.04\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Tokenizer character\r\n",
    "tk_char = tf.keras.preprocessing.text.Tokenizer(num_words=False, lower=False, char_level=True)\r\n",
    "tk_char.fit_on_texts(df.value_x)\r\n",
    "print(\"Number of characters: \" + str(len(tk_char.word_index)))\r\n",
    "print(tk_char.word_index)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of characters: 69\n",
      "{'0': 1, '5': 2, '3': 3, '2': 4, '1': 5, '4': 6, '7': 7, '6': 8, '8': 9, '9': 10, 'M': 11, 'N': 12, 'a': 13, 'S': 14, 'e': 15, 'A': 16, 'i': 17, '-': 18, '.': 19, 'n': 20, 'E': 21, 'r': 22, 'o': 23, 'L': 24, 'O': 25, 'R': 26, 'Y': 27, 'I': 28, 'T': 29, 'F': 30, 'l': 31, 's': 32, 'C': 33, 'u': 34, 'h': 35, 't': 36, 'D': 37, 'H': 38, 'K': 39, 'G': 40, 'W': 41, 'B': 42, 'd': 43, 'P': 44, 'm': 45, 'g': 46, 'k': 47, 'V': 48, 'U': 49, ' ': 50, 'c': 51, 'y': 52, 'b': 53, 'v': 54, 'J': 55, 'z': 56, 'p': 57, 'f': 58, 'w': 59, 'j': 60, 'Z': 61, 'X': 62, 'Q': 63, 'x': 64, 'q': 65, \"'\": 66, '*': 67, ';': 68, '/': 69}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Tokenizer attribute\r\n",
    "tk_attr = tf.keras.preprocessing.text.Tokenizer(num_words=False, filters='', lower=False, char_level=False, split=\"nosplit\")\r\n",
    "tk_attr.fit_on_texts(df.attribute)\r\n",
    "print(\"Number of attributs: \" + str(len(tk_attr.word_index)))\r\n",
    "print(tk_attr.word_index)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of attributs: 15\n",
      "{'f_name': 1, 'l_name': 2, 'gender': 3, 'area_code': 4, 'phone': 5, 'city': 6, 'state': 7, 'zip': 8, 'marital_status': 9, 'has_child': 10, 'salary': 11, 'rate': 12, 'single_exemp': 13, 'married_exemp': 14, 'child_exemp': 15}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Example\r\n",
    "print('Characters: ' + df.value_x[3])\r\n",
    "print(np.array(tf.keras.preprocessing.sequence.pad_sequences(tk_char.texts_to_sequences([df.value_x[3]]), maxlen=maxlen, padding='post')))\r\n",
    "print()\r\n",
    "print('Attribut: ' + df.attribute[3])\r\n",
    "print(tk_attr.texts_to_sequences([df.attribute[3]]))\r\n",
    "print()\r\n",
    "print('Value: ' + str(df.value[3]))\r\n",
    "print(tf.keras.utils.to_categorical([df.value[3]], num_classes=2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Characters: 508\n",
      "[[2 1 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      "Attribut: area_code\n",
      "[[4]]\n",
      "\n",
      "Value: 0\n",
      "[[1. 0.]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "5) Generate a Train- and Testset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Number of tupels for training\r\n",
    "n = 20\r\n",
    "\r\n",
    "train = df[df['id_'].isin(ID_Alle['id_'])]\r\n",
    "train_ID = ID_Alle['id_']\r\n",
    "\r\n",
    "train_ID_Rest = ID_Alle['id_']\r\n",
    "train_Rest = df[df['id_'].isin(train_ID_Rest)]\r\n",
    "\r\n",
    "train_ID_Manuel_List = []\r\n",
    "\r\n",
    "# Iterate for choosing the next observation\r\n",
    "for i in range(0,n):\r\n",
    "    # For prefering empty value_x we have to compute the number of this\r\n",
    "    empty = train_Rest.groupby(['id_'])['empty1'].agg('sum')\r\n",
    "    count = train_Rest.groupby(['id_']).size().to_frame()\r\n",
    "    count['empty1'] = empty\r\n",
    "    count = count.sort_values(by=[0,'empty1'], ascending=False)\r\n",
    "    count.reset_index(inplace=True)\r\n",
    "    count = count[count[0]==count[0].max()]\r\n",
    "    count = count[count['empty1']==count['empty1'].max()]\r\n",
    "    train_ID_Manuel_List.append(count.sample(1, random_state=1)['id_'])\r\n",
    "    train_ID_Manuel = pd.Series(train_ID_Manuel_List)\r\n",
    "    train_Manuel = df[df['id_'].isin(train_ID_Manuel)]\r\n",
    "    train_Rest = train_Rest[~train_Rest.concat.isin(train_Manuel.concat)]\r\n",
    "    train_ID_Rest = train_ID[~train_ID.isin(train_ID_Manuel)]\r\n",
    "\r\n",
    "print('Number of train-tupels: ' + str(len(train_ID_Manuel)))\r\n",
    "\r\n",
    "# The records which we dont need for training we use for the testing\r\n",
    "test_ID = train_ID_Rest.copy()\r\n",
    "test = df[df['id_'].isin(test_ID)]\r\n",
    "\r\n",
    "del i, count, train_ID_Manuel_List, empty, train_ID, train, train_ID_Rest, train_Rest"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of train-tupels: 20\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Transform the text to numbers\r\n",
    "X_train_Manuel=np.array(tf.keras.preprocessing.sequence.pad_sequences(tk_char.texts_to_sequences(train_Manuel.value_x), maxlen=maxlen, padding='post'))\r\n",
    "X_train_Manuel_attribute=np.array(tk_attr.texts_to_sequences(train_Manuel.attribute))\r\n",
    "Y_train_Manuel=tf.keras.utils.to_categorical(train_Manuel.value, num_classes=2)\r\n",
    "\r\n",
    "X_test=np.array(tf.keras.preprocessing.sequence.pad_sequences(tk_char.texts_to_sequences(test.value_x), maxlen=maxlen, padding='post'))\r\n",
    "X_test_attribute=np.array(tk_attr.texts_to_sequences(test.attribute))\r\n",
    "Y_test=tf.keras.utils.to_categorical(test.value, num_classes=2)\r\n",
    "\r\n",
    "#X_train_Rest=np.array(tf.keras.preprocessing.sequence.pad_sequences(tk_char.texts_to_sequences(train_Rest.value_x), maxlen=maxlen, padding='post'))\r\n",
    "#X_train_Rest_attribute=np.array(tk_attr.texts_to_sequences(train_Rest.attribute))\r\n",
    "#Y_train_Rest=tf.keras.utils.to_categorical(train_Rest.value, num_classes=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# New random examples 1 (specific length)\r\n",
    "#Y_rand_obs=Y_rand_obs = np.zeros((new_example*len(tk_attr.word_index),2))\r\n",
    "#Y_rand_obs[:,1]=1\r\n",
    "\r\n",
    "#i=0\r\n",
    "#for attr in attribute['name']:\r\n",
    "#    X_rand_obs_attribute_1 = np.zeros((new_example,1))\r\n",
    "#    X_rand_obs_attribute_1[:,0]=np.array(tk_attr.texts_to_sequences([attr]))\r\n",
    "#    maxnumchar = attribute.loc[attribute['name']==attr]['maxnumchar'].to_numpy()[0]\r\n",
    "#    X_rand_obs_1=np.ndarray.round(np.random.rand(new_example,maxnumchar)*len(tk_char.word_index),)\r\n",
    "#    X_rand_obs_1=np.array(tf.keras.preprocessing.sequence.pad_sequences(X_rand_obs_1, maxlen=maxlen, padding='post'))\r\n",
    "\r\n",
    "#    if i==0:\r\n",
    "#        X_rand_obs_attribute=X_rand_obs_attribute_1\r\n",
    "#        X_rand_obs=X_rand_obs_1\r\n",
    "#    else:\r\n",
    "#        X_rand_obs_attribute=np.append(X_rand_obs_attribute,X_rand_obs_attribute_1,axis=0)\r\n",
    "#        X_rand_obs=np.append(X_rand_obs,X_rand_obs_1,axis=0)\r\n",
    "#    i=+1\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# New random examples 2\r\n",
    "#X_rand_obs=np.ndarray.round(np.random.rand(new_example*len(tk_attr.word_index),X_train_Manuel_1.shape[1])*len(tk_char.word_index),)\r\n",
    "#X_rand_obs_attribute=X_train_Manuel_attribute_1[0:X_rand_obs.shape[0]]\r\n",
    "#Y_rand_obs = np.zeros((new_example*len(tk_attr.word_index),2))\r\n",
    "#Y_rand_obs[:,1]=1\r\n",
    "\r\n",
    "#X_rand_obs_attribute_1=X_train_Manuel_attribute_1[0:len(tk_attr.word_index)]\r\n",
    "#X_rand_obs_attribute=X_rand_obs_attribute_1.copy()\r\n",
    "#for i in range(1,new_example):\r\n",
    "#    X_rand_obs_attribute=np.append(X_rand_obs_attribute,X_rand_obs_attribute_1,axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "#X_train_Manuel=np.append(X_train_Manuel_1,X_rand_obs,axis=0)\r\n",
    "#X_train_Manuel_attribute=np.append(X_train_Manuel_attribute_1,X_rand_obs_attribute,axis=0)\r\n",
    "#Y_train_Manuel=np.append(Y_train_Manuel_1,Y_rand_obs,axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Number of correct (0) and wrong (1) data in the trainset\r\n",
    "np.ndarray.sum(Y_train_Manuel,axis=0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([293.,   7.], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define model TSB-RNN and ETSB-RNN."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Parameter for models\r\n",
    "n_classes = 2\r\n",
    "ver=1\r\n",
    "\r\n",
    "# Hyperparameter\r\n",
    "n_epochs = 120\r\n",
    "batch_size=round(attribute.shape[0]*5)\r\n",
    "#batch_size=round(attribute.shape[0]*n/4)\r\n",
    "#batch_size=round(X_train_Manuel.shape[0])\r\n",
    "\r\n",
    "emb_dim_char = round(len(tk_char.word_index)+1)\r\n",
    "emb_dim_attr = round(len(tk_attr.word_index)+1)\r\n",
    "rnn_dim = 64\r\n",
    "rnn_dim_att = 8"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Define TSB-RNN\r\n",
    "tf.keras.backend.clear_session()\r\n",
    "checkpoint_path = 'checkpoint/' + data + 'p11/checkpoint_p11_m0'\r\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\r\n",
    "    filepath=checkpoint_path,\r\n",
    "    monitor='loss',\r\n",
    "    save_best_only=True,\r\n",
    "    save_weights_only=True,\r\n",
    "    verbose=ver\r\n",
    ")\r\n",
    "\r\n",
    "inputA = tf.keras.Input(shape=(maxlen,))\r\n",
    "\r\n",
    "a = tf.keras.layers.Embedding(emb_dim_char,emb_dim_char,mask_zero=True)(inputA)\r\n",
    "\r\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(units=rnn_dim, return_sequences=True))(a)\r\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(units=rnn_dim, return_sequences=False))(x)\r\n",
    "x = tf.keras.layers.Dense(round(rnn_dim/2), activation=\"relu\")(x)\r\n",
    "x = tf.keras.layers.BatchNormalization()(x)\r\n",
    "z = tf.keras.layers.Dense(n_classes, activation='softmax')(x)\r\n",
    "\r\n",
    "model = tf.keras.models.Model(inputs=inputA, outputs=z)\r\n",
    "\r\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\r\n",
    "\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 27)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 27, 70)            4900      \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 27, 128)           17280     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               24704     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 51,206\n",
      "Trainable params: 51,142\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Train TSB-RNN\r\n",
    "#log = model.fit(X_train_Manuel, Y_train_Manuel, shuffle=False, batch_size=batch_size, epochs=n_epochs, validation_data=(X_test, Y_test), callbacks=[checkpoint], verbose=ver)\r\n",
    "log = model.fit(X_train_Manuel, Y_train_Manuel, shuffle=False, batch_size=batch_size, epochs=n_epochs, callbacks=[checkpoint], verbose=ver)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/120\n",
      "4/4 [==============================] - 3s 18ms/step - loss: 0.7934 - accuracy: 0.6533\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.79342, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 2/120\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6854 - accuracy: 0.7067\n",
      "\n",
      "Epoch 00002: loss improved from 0.79342 to 0.68542, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 3/120\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6199 - accuracy: 0.7767\n",
      "\n",
      "Epoch 00003: loss improved from 0.68542 to 0.61988, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 4/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5868 - accuracy: 0.8300\n",
      "\n",
      "Epoch 00004: loss improved from 0.61988 to 0.58684, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 5/120\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5692 - accuracy: 0.8433\n",
      "\n",
      "Epoch 00005: loss improved from 0.58684 to 0.56924, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 6/120\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5518 - accuracy: 0.8833\n",
      "\n",
      "Epoch 00006: loss improved from 0.56924 to 0.55179, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 7/120\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5387 - accuracy: 0.8733\n",
      "\n",
      "Epoch 00007: loss improved from 0.55179 to 0.53867, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 8/120\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5110 - accuracy: 0.9433\n",
      "\n",
      "Epoch 00008: loss improved from 0.53867 to 0.51102, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 9/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4862 - accuracy: 0.9633\n",
      "\n",
      "Epoch 00009: loss improved from 0.51102 to 0.48622, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 10/120\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4698 - accuracy: 0.9533\n",
      "\n",
      "Epoch 00010: loss improved from 0.48622 to 0.46983, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 11/120\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4600 - accuracy: 0.9600\n",
      "\n",
      "Epoch 00011: loss improved from 0.46983 to 0.45999, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 12/120\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4359 - accuracy: 0.9667\n",
      "\n",
      "Epoch 00012: loss improved from 0.45999 to 0.43592, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 13/120\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4229 - accuracy: 0.9800\n",
      "\n",
      "Epoch 00013: loss improved from 0.43592 to 0.42293, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 14/120\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4055 - accuracy: 0.9767\n",
      "\n",
      "Epoch 00014: loss improved from 0.42293 to 0.40545, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 15/120\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3829 - accuracy: 0.9833\n",
      "\n",
      "Epoch 00015: loss improved from 0.40545 to 0.38293, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 16/120\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.3717 - accuracy: 0.9800\n",
      "\n",
      "Epoch 00016: loss improved from 0.38293 to 0.37172, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 17/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3517 - accuracy: 0.9933\n",
      "\n",
      "Epoch 00017: loss improved from 0.37172 to 0.35174, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 18/120\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3347 - accuracy: 0.9967\n",
      "\n",
      "Epoch 00018: loss improved from 0.35174 to 0.33473, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 19/120\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.3312 - accuracy: 0.9900\n",
      "\n",
      "Epoch 00019: loss improved from 0.33473 to 0.33118, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 20/120\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3093 - accuracy: 0.9933\n",
      "\n",
      "Epoch 00020: loss improved from 0.33118 to 0.30933, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 21/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2914 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00021: loss improved from 0.30933 to 0.29138, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 22/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.2773 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00022: loss improved from 0.29138 to 0.27728, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 23/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2656 - accuracy: 0.9967\n",
      "\n",
      "Epoch 00023: loss improved from 0.27728 to 0.26564, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 24/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2539 - accuracy: 0.9967\n",
      "\n",
      "Epoch 00024: loss improved from 0.26564 to 0.25393, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 25/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.2403 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00025: loss improved from 0.25393 to 0.24032, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 26/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.2312 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00026: loss improved from 0.24032 to 0.23121, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 27/120\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.2172 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00027: loss improved from 0.23121 to 0.21722, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 28/120\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.2095 - accuracy: 0.9967\n",
      "\n",
      "Epoch 00028: loss improved from 0.21722 to 0.20954, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 29/120\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1977 - accuracy: 0.9967\n",
      "\n",
      "Epoch 00029: loss improved from 0.20954 to 0.19766, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 30/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1845 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00030: loss improved from 0.19766 to 0.18455, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 31/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1731 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00031: loss improved from 0.18455 to 0.17313, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 32/120\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1664 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00032: loss improved from 0.17313 to 0.16639, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 33/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1603 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00033: loss improved from 0.16639 to 0.16032, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 34/120\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1527 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00034: loss improved from 0.16032 to 0.15267, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 35/120\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1433 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00035: loss improved from 0.15267 to 0.14330, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 36/120\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1333 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00036: loss improved from 0.14330 to 0.13328, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 37/120\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1241 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00037: loss improved from 0.13328 to 0.12412, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 38/120\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1182 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00038: loss improved from 0.12412 to 0.11819, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 39/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1116 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00039: loss improved from 0.11819 to 0.11158, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 40/120\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1070 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00040: loss improved from 0.11158 to 0.10698, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 41/120\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1010 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00041: loss improved from 0.10698 to 0.10096, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 42/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0940 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00042: loss improved from 0.10096 to 0.09405, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 43/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0884 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00043: loss improved from 0.09405 to 0.08836, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 44/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0845 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00044: loss improved from 0.08836 to 0.08449, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 45/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0795 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00045: loss improved from 0.08449 to 0.07948, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 46/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0734 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00046: loss improved from 0.07948 to 0.07341, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 47/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0687 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00047: loss improved from 0.07341 to 0.06872, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 48/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0644 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00048: loss improved from 0.06872 to 0.06438, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 49/120\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0626 - accuracy: 0.9967\n",
      "\n",
      "Epoch 00049: loss improved from 0.06438 to 0.06256, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 50/120\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0562 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00050: loss improved from 0.06256 to 0.05621, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 51/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0526 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00051: loss improved from 0.05621 to 0.05259, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 52/120\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0493 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00052: loss improved from 0.05259 to 0.04925, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 53/120\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0472 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00053: loss improved from 0.04925 to 0.04723, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 54/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0434 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00054: loss improved from 0.04723 to 0.04344, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 55/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0397 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00055: loss improved from 0.04344 to 0.03970, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 56/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0361 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00056: loss improved from 0.03970 to 0.03612, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 57/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0335 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00057: loss improved from 0.03612 to 0.03348, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 58/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0321 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00058: loss improved from 0.03348 to 0.03208, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 59/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0303 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00059: loss improved from 0.03208 to 0.03026, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 60/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0286 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00060: loss improved from 0.03026 to 0.02856, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 61/120\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0273 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00061: loss improved from 0.02856 to 0.02734, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 62/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0238 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00062: loss improved from 0.02734 to 0.02377, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 63/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0217 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00063: loss improved from 0.02377 to 0.02171, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 64/120\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0203 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00064: loss improved from 0.02171 to 0.02031, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 65/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0197 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00065: loss improved from 0.02031 to 0.01971, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 66/120\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0178 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00066: loss improved from 0.01971 to 0.01781, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 67/120\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00067: loss improved from 0.01781 to 0.01698, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 68/120\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.0151 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00068: loss improved from 0.01698 to 0.01507, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 69/120\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00069: loss improved from 0.01507 to 0.01353, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 70/120\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0122 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00070: loss improved from 0.01353 to 0.01221, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 71/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0115 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00071: loss improved from 0.01221 to 0.01153, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 72/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0107 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00072: loss improved from 0.01153 to 0.01068, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 73/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00073: loss improved from 0.01068 to 0.00961, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 74/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00074: loss improved from 0.00961 to 0.00906, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 75/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00075: loss improved from 0.00906 to 0.00840, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 76/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00076: loss improved from 0.00840 to 0.00767, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 77/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00077: loss improved from 0.00767 to 0.00706, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 78/120\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00078: loss improved from 0.00706 to 0.00641, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 79/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00079: loss improved from 0.00641 to 0.00582, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 80/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00080: loss improved from 0.00582 to 0.00525, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 81/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00081: loss improved from 0.00525 to 0.00486, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 82/120\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00082: loss improved from 0.00486 to 0.00465, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 83/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00083: loss improved from 0.00465 to 0.00442, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 84/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00084: loss improved from 0.00442 to 0.00400, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 85/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00085: loss improved from 0.00400 to 0.00341, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 86/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00086: loss improved from 0.00341 to 0.00312, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 87/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00087: loss improved from 0.00312 to 0.00286, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 88/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00088: loss improved from 0.00286 to 0.00275, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 89/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00089: loss improved from 0.00275 to 0.00264, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 90/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00090: loss improved from 0.00264 to 0.00233, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 91/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00091: loss improved from 0.00233 to 0.00211, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 92/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00092: loss improved from 0.00211 to 0.00188, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 93/120\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00093: loss improved from 0.00188 to 0.00169, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 94/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00094: loss improved from 0.00169 to 0.00158, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 95/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00095: loss improved from 0.00158 to 0.00152, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 96/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00096: loss improved from 0.00152 to 0.00136, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 97/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00097: loss improved from 0.00136 to 0.00121, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 98/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00098: loss improved from 0.00121 to 0.00113, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 99/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00099: loss improved from 0.00113 to 0.00104, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 100/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 9.0778e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00100: loss improved from 0.00104 to 0.00091, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 101/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 8.2186e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00101: loss improved from 0.00091 to 0.00082, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 102/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 7.6937e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00102: loss improved from 0.00082 to 0.00077, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 103/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 7.5997e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00103: loss improved from 0.00077 to 0.00076, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 104/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 6.9944e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00104: loss improved from 0.00076 to 0.00070, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 105/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 6.0415e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00105: loss improved from 0.00070 to 0.00060, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 106/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 5.0939e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00106: loss improved from 0.00060 to 0.00051, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 107/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 4.6116e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00107: loss improved from 0.00051 to 0.00046, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 108/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 4.2430e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00108: loss improved from 0.00046 to 0.00042, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 109/120\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 4.0101e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00109: loss improved from 0.00042 to 0.00040, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 110/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 3.7247e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00110: loss improved from 0.00040 to 0.00037, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 111/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 3.5262e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00111: loss improved from 0.00037 to 0.00035, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 112/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 3.3916e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00112: loss improved from 0.00035 to 0.00034, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 113/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.9472e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00113: loss improved from 0.00034 to 0.00029, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 114/120\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 2.6322e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00114: loss improved from 0.00029 to 0.00026, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 115/120\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 2.2425e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00115: loss improved from 0.00026 to 0.00022, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 116/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.9752e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00116: loss improved from 0.00022 to 0.00020, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 117/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.7898e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00117: loss improved from 0.00020 to 0.00018, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 118/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.6284e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00118: loss improved from 0.00018 to 0.00016, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 119/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.5551e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00119: loss improved from 0.00016 to 0.00016, saving model to checkpoint/p11/Tax\\checkpoint_p11_m0\n",
      "Epoch 120/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.6317e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00120: loss did not improve from 0.00016\n"
     ]
    }
   ],
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Define ETSB-RNN\r\n",
    "tf.keras.backend.clear_session()\r\n",
    "checkpoint_path1 = 'checkpoint/' + data + 'p11/checkpoint_p11_m1'\r\n",
    "checkpoint1 = tf.keras.callbacks.ModelCheckpoint(\r\n",
    "    filepath=checkpoint_path1,\r\n",
    "    monitor='loss',\r\n",
    "    save_best_only=True,\r\n",
    "    save_weights_only=True,\r\n",
    "    verbose=ver\r\n",
    ")\r\n",
    "\r\n",
    "inputA = tf.keras.Input(shape=(maxlen,))\r\n",
    "inputB = tf.keras.Input(shape=(1,))\r\n",
    "\r\n",
    "a = tf.keras.layers.Embedding(emb_dim_char,emb_dim_char,mask_zero=True)(inputA)\r\n",
    "b = tf.keras.layers.Embedding(emb_dim_attr,emb_dim_attr)(inputB)\r\n",
    "\r\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(units=rnn_dim, return_sequences=True))(a)\r\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(units=rnn_dim, return_sequences=False))(x)\r\n",
    "x = tf.keras.models.Model(inputs=inputA, outputs=x)\r\n",
    "\r\n",
    "y = tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(units=rnn_dim_att, return_sequences=True))(b)\r\n",
    "y = tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(units=rnn_dim_att, return_sequences=False))(y)\r\n",
    "y = tf.keras.models.Model(inputs=inputB, outputs=y)\r\n",
    "\r\n",
    "combined = tf.keras.layers.concatenate([x.output, y.output])\r\n",
    "combined = tf.keras.layers.Dense(round(rnn_dim/2), activation=\"relu\")(combined)\r\n",
    "combined = tf.keras.layers.BatchNormalization()(combined)\r\n",
    "z = tf.keras.layers.Dense(n_classes, activation='softmax')(combined)\r\n",
    "\r\n",
    "model1 = tf.keras.models.Model(inputs=[x.input, y.input], outputs=z)\r\n",
    "model1.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\r\n",
    "model1.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 27)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 27, 70)       4900        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 16)        256         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 27, 128)      17280       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 1, 16)        400         embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 128)          24704       bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 16)           400         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 144)          0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           4640        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32)           128         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            66          batch_normalization[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 52,774\n",
      "Trainable params: 52,710\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# Train ETSB-RNN\r\n",
    "#log1 = model1.fit(x=[X_train_Manuel,X_train_Manuel_attribute], y=Y_train_Manuel, shuffle=False, batch_size=batch_size, epochs=n_epochs, validation_data=([X_test,X_test_attribute], Y_test), callbacks=[checkpoint1], verbose=ver)\r\n",
    "log1 = model1.fit(x=[X_train_Manuel,X_train_Manuel_attribute], y=Y_train_Manuel, shuffle=False, batch_size=batch_size, epochs=n_epochs, callbacks=[checkpoint1], verbose=ver)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/120\n",
      "4/4 [==============================] - 7s 20ms/step - loss: 0.7938 - accuracy: 0.5300\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.79377, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 2/120\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6817 - accuracy: 0.6433\n",
      "\n",
      "Epoch 00002: loss improved from 0.79377 to 0.68173, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 3/120\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6372 - accuracy: 0.7467\n",
      "\n",
      "Epoch 00003: loss improved from 0.68173 to 0.63719, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 4/120\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6070 - accuracy: 0.8567\n",
      "\n",
      "Epoch 00004: loss improved from 0.63719 to 0.60697, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 5/120\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5913 - accuracy: 0.8433\n",
      "\n",
      "Epoch 00005: loss improved from 0.60697 to 0.59126, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 6/120\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5715 - accuracy: 0.9033\n",
      "\n",
      "Epoch 00006: loss improved from 0.59126 to 0.57154, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 7/120\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.5519 - accuracy: 0.8900\n",
      "\n",
      "Epoch 00007: loss improved from 0.57154 to 0.55191, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 8/120\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.5274 - accuracy: 0.9133\n",
      "\n",
      "Epoch 00008: loss improved from 0.55191 to 0.52739, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 9/120\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5070 - accuracy: 0.9233\n",
      "\n",
      "Epoch 00009: loss improved from 0.52739 to 0.50701, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 10/120\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4874 - accuracy: 0.9267\n",
      "\n",
      "Epoch 00010: loss improved from 0.50701 to 0.48738, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 11/120\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4691 - accuracy: 0.9467\n",
      "\n",
      "Epoch 00011: loss improved from 0.48738 to 0.46909, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 12/120\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4454 - accuracy: 0.9767\n",
      "\n",
      "Epoch 00012: loss improved from 0.46909 to 0.44535, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 13/120\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4241 - accuracy: 0.9933\n",
      "\n",
      "Epoch 00013: loss improved from 0.44535 to 0.42411, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 14/120\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4055 - accuracy: 0.9900\n",
      "\n",
      "Epoch 00014: loss improved from 0.42411 to 0.40550, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 15/120\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.3873 - accuracy: 0.9900\n",
      "\n",
      "Epoch 00015: loss improved from 0.40550 to 0.38734, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 16/120\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3721 - accuracy: 0.9933\n",
      "\n",
      "Epoch 00016: loss improved from 0.38734 to 0.37207, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 17/120\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.3555 - accuracy: 0.9900\n",
      "\n",
      "Epoch 00017: loss improved from 0.37207 to 0.35547, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 18/120\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3409 - accuracy: 0.9933\n",
      "\n",
      "Epoch 00018: loss improved from 0.35547 to 0.34086, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 19/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3257 - accuracy: 0.9967\n",
      "\n",
      "Epoch 00019: loss improved from 0.34086 to 0.32567, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 20/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3123 - accuracy: 0.9967\n",
      "\n",
      "Epoch 00020: loss improved from 0.32567 to 0.31231, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 21/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3033 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00021: loss improved from 0.31231 to 0.30332, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 22/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2863 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00022: loss improved from 0.30332 to 0.28630, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 23/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2698 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00023: loss improved from 0.28630 to 0.26975, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 24/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2573 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00024: loss improved from 0.26975 to 0.25732, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 25/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.2452 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00025: loss improved from 0.25732 to 0.24525, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 26/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2370 - accuracy: 0.9900\n",
      "\n",
      "Epoch 00026: loss improved from 0.24525 to 0.23700, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 27/120\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.2313 - accuracy: 0.9967\n",
      "\n",
      "Epoch 00027: loss improved from 0.23700 to 0.23134, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 28/120\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.2143 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00028: loss improved from 0.23134 to 0.21430, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 29/120\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.2010 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00029: loss improved from 0.21430 to 0.20105, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 30/120\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1900 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00030: loss improved from 0.20105 to 0.19003, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 31/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1819 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00031: loss improved from 0.19003 to 0.18194, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 32/120\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1728 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00032: loss improved from 0.18194 to 0.17277, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 33/120\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1673 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00033: loss improved from 0.17277 to 0.16729, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 34/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1577 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00034: loss improved from 0.16729 to 0.15767, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 35/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1455 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00035: loss improved from 0.15767 to 0.14550, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 36/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1360 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00036: loss improved from 0.14550 to 0.13598, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 37/120\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1280 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00037: loss improved from 0.13598 to 0.12802, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 38/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1200 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00038: loss improved from 0.12802 to 0.12000, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 39/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1170 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00039: loss improved from 0.12000 to 0.11705, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 40/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1104 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00040: loss improved from 0.11705 to 0.11038, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 41/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1041 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00041: loss improved from 0.11038 to 0.10408, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 42/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0948 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00042: loss improved from 0.10408 to 0.09478, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 43/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0885 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00043: loss improved from 0.09478 to 0.08846, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 44/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0832 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00044: loss improved from 0.08846 to 0.08324, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 45/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0775 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00045: loss improved from 0.08324 to 0.07750, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 46/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0738 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00046: loss improved from 0.07750 to 0.07378, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 47/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0728 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00047: loss improved from 0.07378 to 0.07280, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 48/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0640 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00048: loss improved from 0.07280 to 0.06396, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 49/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0588 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00049: loss improved from 0.06396 to 0.05884, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 50/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0549 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00050: loss improved from 0.05884 to 0.05493, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 51/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0530 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00051: loss improved from 0.05493 to 0.05298, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 52/120\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0514 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00052: loss improved from 0.05298 to 0.05144, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 53/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0453 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00053: loss improved from 0.05144 to 0.04529, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 54/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0409 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00054: loss improved from 0.04529 to 0.04089, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 55/120\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0378 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00055: loss improved from 0.04089 to 0.03780, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 56/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0355 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00056: loss improved from 0.03780 to 0.03552, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 57/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0352 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00057: loss improved from 0.03552 to 0.03523, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 58/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0352 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00058: loss improved from 0.03523 to 0.03518, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 59/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0295 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00059: loss improved from 0.03518 to 0.02946, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 60/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0270 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00060: loss improved from 0.02946 to 0.02696, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 61/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0247 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00061: loss improved from 0.02696 to 0.02465, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 62/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0231 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00062: loss improved from 0.02465 to 0.02306, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 63/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0217 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00063: loss improved from 0.02306 to 0.02171, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 64/120\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0207 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00064: loss improved from 0.02171 to 0.02070, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 65/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0191 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00065: loss improved from 0.02070 to 0.01906, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 66/120\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0174 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00066: loss improved from 0.01906 to 0.01744, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 67/120\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0157 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00067: loss improved from 0.01744 to 0.01573, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 68/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00068: loss improved from 0.01573 to 0.01445, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 69/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00069: loss improved from 0.01445 to 0.01411, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 70/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00070: loss improved from 0.01411 to 0.01365, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 71/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0120 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00071: loss improved from 0.01365 to 0.01195, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 72/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00072: loss improved from 0.01195 to 0.01058, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 73/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00073: loss improved from 0.01058 to 0.00974, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 74/120\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00074: loss improved from 0.00974 to 0.00889, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 75/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00075: loss improved from 0.00889 to 0.00863, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 76/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00076: loss improved from 0.00863 to 0.00804, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 77/120\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00077: loss improved from 0.00804 to 0.00714, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 78/120\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00078: loss improved from 0.00714 to 0.00661, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 79/120\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00079: loss improved from 0.00661 to 0.00629, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 80/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00080: loss improved from 0.00629 to 0.00593, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 81/120\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00081: loss improved from 0.00593 to 0.00514, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 82/120\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00082: loss improved from 0.00514 to 0.00498, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 83/120\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00083: loss improved from 0.00498 to 0.00496, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 84/120\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00084: loss improved from 0.00496 to 0.00428, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 85/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00085: loss improved from 0.00428 to 0.00367, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 86/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00086: loss improved from 0.00367 to 0.00330, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 87/120\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00087: loss improved from 0.00330 to 0.00300, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 88/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00088: loss improved from 0.00300 to 0.00275, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 89/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00089: loss improved from 0.00275 to 0.00254, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 90/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00090: loss improved from 0.00254 to 0.00253, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 91/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00091: loss did not improve from 0.00253\n",
      "Epoch 92/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00092: loss improved from 0.00253 to 0.00231, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 93/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00093: loss improved from 0.00231 to 0.00185, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 94/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00094: loss improved from 0.00185 to 0.00166, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 95/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00095: loss improved from 0.00166 to 0.00150, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 96/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00096: loss improved from 0.00150 to 0.00137, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 97/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00097: loss improved from 0.00137 to 0.00126, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 98/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00098: loss improved from 0.00126 to 0.00117, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 99/120\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00099: loss improved from 0.00117 to 0.00111, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 100/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00100: loss improved from 0.00111 to 0.00110, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 101/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00101: loss improved from 0.00110 to 0.00104, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 102/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 8.8437e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00102: loss improved from 0.00104 to 0.00088, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 103/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 7.6220e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00103: loss improved from 0.00088 to 0.00076, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 104/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 6.9025e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00104: loss improved from 0.00076 to 0.00069, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 105/120\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 6.8963e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00105: loss improved from 0.00069 to 0.00069, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 106/120\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 6.3602e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00106: loss improved from 0.00069 to 0.00064, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 107/120\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 5.2349e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00107: loss improved from 0.00064 to 0.00052, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 108/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 4.6759e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00108: loss improved from 0.00052 to 0.00047, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 109/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 4.2626e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00109: loss improved from 0.00047 to 0.00043, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 110/120\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 3.9076e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00110: loss improved from 0.00043 to 0.00039, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 111/120\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 3.6858e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00111: loss improved from 0.00039 to 0.00037, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 112/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 3.7080e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00112: loss did not improve from 0.00037\n",
      "Epoch 113/120\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 3.4186e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00113: loss improved from 0.00037 to 0.00034, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 114/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 3.1805e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00114: loss improved from 0.00034 to 0.00032, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 115/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.6984e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00115: loss improved from 0.00032 to 0.00027, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 116/120\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 2.3380e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00116: loss improved from 0.00027 to 0.00023, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 117/120\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 2.0833e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00117: loss improved from 0.00023 to 0.00021, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 118/120\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.8546e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00118: loss improved from 0.00021 to 0.00019, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 119/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.6663e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00119: loss improved from 0.00019 to 0.00017, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n",
      "Epoch 120/120\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.5281e-04 - accuracy: 1.0000\n",
      "\n",
      "Epoch 00120: loss improved from 0.00017 to 0.00015, saving model to checkpoint/p11/Tax\\checkpoint_p11_m1\n"
     ]
    }
   ],
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Load best weights\r\n",
    "model.load_weights(checkpoint_path)\r\n",
    "model1.load_weights(checkpoint_path1)\r\n",
    "\r\n",
    "# Evaluate with testsets\r\n",
    "scores = model.evaluate(X_test, Y_test)\r\n",
    "print('model')\r\n",
    "print(str(model.metrics_names[0])+': '+str(scores[0]))\r\n",
    "print(str(model.metrics_names[1])+': '+str(scores[1]))\r\n",
    "\r\n",
    "scores1 = model1.evaluate([X_test,X_test_attribute], Y_test)\r\n",
    "print('model1')\r\n",
    "print(str(model1.metrics_names[0])+': '+str(scores1[0]))\r\n",
    "print(str(model1.metrics_names[1])+': '+str(scores1[1]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "93741/93741 [==============================] - 723s 8ms/step - loss: 0.0431 - accuracy: 0.9964\n",
      "model\n",
      "loss: 0.04310808330774307\n",
      "accuracy: 0.9964406490325928\n",
      "93741/93741 [==============================] - 778s 8ms/step - loss: 0.0317 - accuracy: 0.9970\n",
      "model1\n",
      "loss: 0.031671322882175446\n",
      "accuracy: 0.9970313906669617\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "source": [
    "# Plot results over epochs ETSB-RNN\r\n",
    "#plt.plot(log.history['loss'], label='Training')\r\n",
    "#plt.plot(log.history['val_loss'], label='Testing')\r\n",
    "#plt.legend()\r\n",
    "#plt.grid()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "source": [
    "# Plot results over epochs ETSB-RNN\r\n",
    "#plt.plot(log1.history['loss'], label='Training')\r\n",
    "#plt.plot(log1.history['val_loss'], label='Testing')\r\n",
    "#plt.legend()\r\n",
    "#plt.grid()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Predict testdataset\r\n",
    "Y_test_disc = np.argmax(Y_test, axis=1)\r\n",
    "\r\n",
    "Y_pred = model.predict(X_test)\r\n",
    "Y_pred_disc = np.argmax(Y_pred, axis=1)\r\n",
    "\r\n",
    "Y_pred1 = model1.predict([X_test,X_test_attribute])\r\n",
    "Y_pred_disc1 = np.argmax(Y_pred1, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# TSB-RNN\r\n",
    "confusion_matrix(Y_test_disc, Y_pred_disc)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[2870532,    7956],\n",
       "       [   2721,  118491]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# ETSB-RNN\r\n",
    "confusion_matrix(Y_test_disc, Y_pred_disc1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[2872149,    6339],\n",
       "       [   2566,  118646]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# Number of errors (1)\r\n",
    "test.groupby('value')['value_x'].count()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "value\n",
       "0    2878488\n",
       "1     121212\n",
       "Name: value_x, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# Measures TSB-RNN\r\n",
    "Summe = test.groupby('value')['value_x'].count()\r\n",
    "print('Error Rate: '+ str(round(100/(Summe[0]+Summe[1])*Summe[1],2)))\r\n",
    "loss = scores[0]\r\n",
    "print('Loss: {:.4f}'.format(loss))\r\n",
    "# accuracy: (tp + tn) / (p + n)\r\n",
    "accuracy = accuracy_score(Y_test_disc, Y_pred_disc)\r\n",
    "print('Accuracy: {:.2f}%'.format(accuracy*100))\r\n",
    "# precision tp / (tp + fp)\r\n",
    "precision = precision_score(Y_test_disc, Y_pred_disc)\r\n",
    "print('Precision: {:.2f}%'.format(precision*100))\r\n",
    "# recall: tp / (tp + fn)\r\n",
    "recall = recall_score(Y_test_disc, Y_pred_disc)\r\n",
    "print('Recall: {:.2f}%'.format(recall*100))\r\n",
    "# f1: 2 tp / (2 tp + fp + fn)\r\n",
    "f1 = f1_score(Y_test_disc, Y_pred_disc)\r\n",
    "print('F1 score: {:.2f}%'.format(f1*100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error Rate: 4.04\n",
      "Loss: 0.0431\n",
      "Accuracy: 99.64%\n",
      "Precision: 93.71%\n",
      "Recall: 97.76%\n",
      "F1 score: 95.69%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# Measures ETSB-RNN\r\n",
    "Summe = test.groupby('value')['value_x'].count()\r\n",
    "print('Error Rate: '+ str(round(100/(Summe[0]+Summe[1])*Summe[1],2)))\r\n",
    "loss = scores1[0]\r\n",
    "print('Loss: {:.4f}'.format(loss))\r\n",
    "# accuracy: (tp + tn) / (p + n)\r\n",
    "accuracy = accuracy_score(Y_test_disc, Y_pred_disc1)\r\n",
    "print('Accuracy: {:.2f}%'.format(accuracy*100))\r\n",
    "# precision tp / (tp + fp)\r\n",
    "precision = precision_score(Y_test_disc, Y_pred_disc1)\r\n",
    "print('Precision: {:.2f}%'.format(precision*100))\r\n",
    "# recall: tp / (tp + fn)\r\n",
    "recall = recall_score(Y_test_disc, Y_pred_disc1)\r\n",
    "print('Recall: {:.2f}%'.format(recall*100))\r\n",
    "# f1: 2 tp / (2 tp + fp + fn)\r\n",
    "f1 = f1_score(Y_test_disc, Y_pred_disc1)\r\n",
    "print('F1 score: {:.2f}%'.format(f1*100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error Rate: 4.04\n",
      "Loss: 0.0317\n",
      "Accuracy: 99.70%\n",
      "Precision: 94.93%\n",
      "Recall: 97.88%\n",
      "F1 score: 96.38%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# Generate dataset with results from TSB-RNN (Model 0) and ETSB-RNN (Model 1)\r\n",
    "df1 = test.copy()\r\n",
    "df1['M0_pred'] = np.round(1-Y_pred[:,0],2)\r\n",
    "df1['M1_pred'] = np.round(1-Y_pred1[:,0],2)\r\n",
    "df1['M0_pred_disc'] = Y_pred_disc\r\n",
    "df1['M1_pred_disc'] = Y_pred_disc1\r\n",
    "df1['M0'] = np.where(df1['M0_pred_disc'] != df1['value'],1,0)\r\n",
    "df1['M1'] = np.where(df1['M1_pred_disc'] != df1['value'],1,0)\r\n",
    "df1['M0_M1'] = np.where((df1['M0_pred_disc'] != df1['value']) & (df1['M1_pred_disc'] != df1['value']),1,0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3074397aa67324493a4e19a94092cddfd49ffb744bae2a6319f30208afef7c2"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.7 64-bit ('env': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}